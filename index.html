<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>SWE-bench</title>
    <meta name="description" content="SWE-bench: Evaluate Language Models on Open Source Software Tasks" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" />
    <meta property="og:image" content="/logo.png" />
    <!-- <link rel="image_src" type="image/png" href="logo.png" /> -->
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
    <link rel="icon" href="favicon.ico" type="image/x-icon" />
    <link rel="stylesheet" href="css/normalize.css" />
    <link rel="stylesheet" href="css/fonts.css" />
    <link rel="stylesheet" href="css/styles.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="..." crossorigin="anonymous" />
  </head>
  <body>
    <header class="header-container">
      <div class="content-wrapper">
        <img src="img/pnlp-logo.svg" style="width: 3em;padding-top:0.5em" />
      </div>
    </header>
    <section style="background-color: #E4F0D0;">
      <div class="content-wrapper title-wrapper" style="flex-direction:column;">
        <h1 style="font-size:60px;">
          SWE-bench
        </h1>
        <h3>
          Evaluate Language Models on Open Source Software Tasks
        </h3>
      </div>
    </section>
    <section class="main-container">
      <!-- Left Column -->
      <div class="content-wrapper">
        <div class="grid-1-2">
          <div class="content-box">
            <h2 class="text-title">News</h2>
            <p><span class="label-date">Oct 10.2023</span> Initial Release</p>
          </div>
          <div class="content-box">
            <h2 class="text-title">What is SWE-bench?</h2>
            <p class="text-content">
              SWE-bench is a benchmark for evaluating language models on open source software tasks.
              Given an <b>issue</b>, a model is asked to generate a <b>patch</b> to fix a
              <b>codebase</b> such that the issue is resolved.
              We collect <b>2294</b> task instances drawn from real GitHub issues and corresponding
              pull requests from <b>12</b> popular Python repositories.
              SWE-bench aims to serve as a testbed for evaluating language models that are more
              practical, intelligent, and autonomous with practical applications in software.
            </p>
            <div class="button-container" style="margin-top:1em;">
              <a class="button unfilled" href="TODO">
                <i class="fa fa-paperclip"></i> Paper
              </a>
            </div>
            <div class="button-container">
              <a class="button unfilled" href="TODO">
                <i class="fab fa-github"></i> GitHub
              </a>
            </div>
          </div>
          <div class="content-box">
            <h2 class="text-title">Download</h2>
            <div class="button-container" style="margin-top:1em;">
              <a class="button unfilled" href="TODO">
                <i class="fa fa-download"></i> Download
              </a>
            </div>
          </div>
          <div class="content-box">
            <h2 class="text-title">Question & Contributing</h2>
            <p class="text-content">
              If you have any questions or would like to contribute to SWE-bench, you can
              post an issue on the SWE-bench <a href="TODO">GitHub issues page</a>.
              Also, please feel free to contact <a href="http://www.carlosejimenez.com/">Carlos Jimenez</a> and
              <a href="https://john-b-yang.github.io/">John Yang</a> directly.
            </p>
          </div>
          <div class="content-box">
            <h2 class="text-title">Acknowledgements</h2>
            <p class="text-content">
              We would like to thank
              <a href="https://www.cs.princeton.edu/~danqic/">Prof. Danqi Chen</a> and the
              <a href="https://princeton-nlp.github.io/">Princeton NLP group</a>
              for their support and valuable feedback
              towards building SWE-bench. We would also like to thank Professor
              <a href="https://tridao.me/">Tri Dao</a> for his guidance
              on training large models. In addition, our thanks to
              <a href="https://pranavrajpurkar.com/">Prof. Pranav Rajpurkar</a> for giving us permission
              to use the <a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD template</a> for this
              website.
            </p>
          </div>
          <div class="content-box">
            <h2 class="text-title">Citing</h2>
            <p class="text-content">
                If you found SWE-bench helpful for your work, please cite us!
            </p>
            <p class="text-content">
                <pre class="code-segment">@inproceedings{jimenez2023swebench,
  title = {SWE-bench: Can Language Models Resolve Real-World GitHub Issues?},
  author = {Jimenez, Carlos E. and Yang, John and Wettig, Alexander and Yao, Shunyu and Pei, Kexin and Press, Ofir and Narasimhan, Karthik},
  booktitle = {ArXiv},
  year = {2023},
}
                </pre>
            </p>
          </div>
        </div>
        <!-- Right Column -->
        <div class="grid-1-2">
          <div class="content-box">
            <h2 class="text-title">Leaderboard</h2>
            <p class="text-content">
              The <b>% Resolved</b> metrics refers to the percentage of SWE-bench tasks (2294 total)
              that were <i>resolved</i> by the model. For this leaderboard, we do not consider
              models that generate based on the "oracle" retrieval setting (correct files to edit are
              given directly to the model).
            </p>
            <table class="content-table">
              <thead>
                <tr>
                  <th>Rank</th>
                  <th>Model</th>
                  <th>% Resolved</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>
                    <p class="rank-number">1.</p>
                    <p><span class="label-date">Oct 10.2023</span></p>
                  </td>
                  <td>
                    <p class="model-type">GPT-3 (Zero-Shot)*</p>
                    <p class="model-owner">OpenAI</p>
                  </td>
                  <td><p class="number">0.7177</p></td>
                </tr>
              </tbody>
            </table>
            <div class="centered-text-container">
              <p class="text-content centralize-text">
                <a href="TODO">Evaluation code</a>
              </p>
            </div>
          </div>
          <div class="content-box">
            <h2 class="text-title">Leaderboard (Patch Generation)</h2>
            <p class="text-content">
              For this leaderboard, we consider models that generate based on the "oracle" retrieval
              setting. "Oracle" retrieval refers to the setting where the correct <i>files</i> to edit
              are given directly to the model. This setting is meant to focus on a model's patch generation
              ability.
            </p>
            <table class="content-table">
              <thead>
                <tr>
                  <th>Rank</th>
                  <th>Model</th>
                  <th>% Resolved</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>
                    <p class="rank-number">1.</p>
                    <p><span class="label-date">Oct 10.2023</span></p>
                  </td>
                  <td>
                    <p class="model-type">GPT-3 (Zero-Shot)*</p>
                    <p class="model-owner">OpenAI</p>
                  </td>
                  <td><p class="number">0.7177</p></td>
                </tr>
              </tbody>
            </table>
            <div class="centered-text-container">
              <p class="text-content centralize-text">
                <a href="TODO">Evaluation code</a>
              </p>
            </div>
          </div>
          <div class="content-box">
            <h2 class="text-title">Leaderboard (Edit Localization)</h2>
            <p class="text-content">
              For this leaderboard, we evaluate models on the task of, given an
              <i>issue</i>, does a model identify the sames files as the corresponding
              reference solution? This task is meant to focus on a model's ability to localize
              the correct files to edit.
              <br><br>
              This task is not directly comparable to the other two tasks since
              the other two tasks require the model to generate a patch. This task only requires
              the model to identify the files that are edited by the reference solution. In addition,
              it is possible for models to edit files not touched by the reference solution and
              still resolve the issue successfully.
            </p>
            <table class="content-table">
              <thead>
                <tr>
                  <th>Rank</th>
                  <th>Model</th>
                  <th>% Resolved</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>
                    <p class="rank-number">1.</p>
                    <p><span class="label-date">Oct 10.2023</span></p>
                  </td>
                  <td>
                    <p class="model-type">GPT-3 (Zero-Shot)*</p>
                    <p class="model-owner">OpenAI</p>
                  </td>
                  <td><p class="number">0.7177</p></td>
                </tr>
              </tbody>
            </table>
            <div class="centered-text-container">
              <p class="text-content centralize-text">
                <a href="TODO">Evaluation code</a>
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <footer class="footer-container">
      <div class="content-wrapper">
        <div class="footer-text"><a href="https://princeton-nlp.github.io/">© Princeton NLP 2023</a></div>
      </div>
    </footer>
  </body>
</html>
